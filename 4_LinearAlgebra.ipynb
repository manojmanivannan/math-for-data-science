{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "linear algebra concerns itself with linear systems but represents them through vector spaces and matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector\n",
    "A vector is an arrow in space with a specific direction and length, often representing a piece of data.\n",
    "\n",
    " $$\\overrightarrow{v} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([3,2])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\overrightarrow{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 1 \\\\ 2 \\end{bmatrix}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and combining vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\overrightarrow{v} = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} \\\\ \\overrightarrow{w} = \\begin{bmatrix} 2 \\\\ -1\\end{bmatrix}$$\n",
    "\n",
    " $$\\overrightarrow{v}+\\overrightarrow{w} = \\begin{bmatrix} 3+2 \\\\ 2-1\\end{bmatrix}=\\begin{bmatrix} 5 \\\\ 1\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([3,2])\n",
    "w = np.array([2,-1])\n",
    "\n",
    "print(v+w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is growing or shrinking a vector’s length. You can grow/shrink a vector by multiplying or scaling it with a single value, known as a scalar\n",
    "\n",
    "![Vector Scaling](images/LinearAlgebra_VectorScaling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 2.]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([3,1])\n",
    "# scale the vector\n",
    "scaled_v = 2.0 * v\n",
    "# display scaled vector\n",
    "print(scaled_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span and Linear Dependence\n",
    "$\\overrightarrow{v}$ and $\\overrightarrow{w}$ are fixed in direction, except for flipping with negative scalars, but we can use scaling to freely create any vector composed of $\\overrightarrow{v} + \\overrightarrow{w}$. This whole space of possible vectors is called span, and in most cases our span can create unlimited vectors off those two vectors, simply by scaling and summing them. When we have two vectors in two different directions, they are linearly independent and have this unlimited span.\n",
    "\n",
    "What happens when two vectors exist in the same direction, or exist on the same line? The combination of those vectors is also stuck on the same line, limiting our span to just that line. No matter how you scale it, the resulting sum vector is also stuck on that same line. This makes them linearly dependent\n",
    "\n",
    "Info:  Determinant to check for linear dependence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Transformations\n",
    "This concept of adding two vectors with fixed direction, but scaling them to get different combined vectors, is hugely important. This combined vector, except in cases of linear dependence, can point in any direction and have any length we choose. This sets up an intuition for linear transformations where we use a vector to transform another vector in a function-like manner."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis Vectors\n",
    "two simple vectors $\\widehat{i}$ and $\\widehat{j}$ (“i-hat” and “j-hat”). These are known as basis vectors, which are used to describe transformations on other vectors. They typically have a length of 1 and point in perpendicular positive directions.\n",
    "\n",
    "![Basis Vectors](images/LinearAlgebra_BasisVectors.png)\n",
    "\n",
    "Our basis vector is expressed in a 2 × 2 matrix, where the first column is  $\\widehat{i}$ and the second column is  $\\widehat{j}$:\n",
    "\n",
    "\\begin{split}\n",
    "\\widehat{i} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\n",
    "\\widehat{j} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\n",
    "\\end{split}\n",
    "\n",
    "$$basis= \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "A matrix is a collection of vectors (such as $\\widehat{i}$, $\\widehat{j}$) that can have multiple rows and columns and is a convenient way to package data. We can use $\\widehat{i}$ and $\\widehat{j}$ to create any vector we want by scaling and adding them.\n",
    "\n",
    "I want vector $\\overrightarrow{v}$ to land at [3, 2]. What happens to $\\overrightarrow{v}$ if we stretch $\\widehat{i}$ by a factor of 3 and $\\widehat{j}$ by a factor of 2? First we scale them individually as shown here:\n",
    "\n",
    "\\begin{split}\n",
    "3\\widehat{i} = 3\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} \\\\\n",
    "2\\widehat{j} = 2\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix}\n",
    "\\end{split}\n",
    "\n",
    "If we stretched space in these two directions, what does this do to $\\overrightarrow{v}$ ? Well, it is going to stretch with $\\widehat{i}$ and $\\widehat{j}$. This is known as a linear transformation, where we transform a vector with stretching, squishing, sheering, or rotating by tracking basis vector movements\n",
    "\n",
    " $$\\overrightarrow{v}_{new} = \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix}$$\n",
    "\n",
    " ![Linear Tranformations](images/LinearAlgebra_Transformations.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Vector Multiplication\n",
    "\n",
    "If you want true linear algebra enlightenment, think why creating vectors and transforming vectors are actually the same thing. It’s all a matter of relativity given your basis vectors being a starting point before and after a transformation. The formula to transform a vector $\\overrightarrow{v}$  given basis vectors $\\widehat{i}$ and $\\widehat{j}$ packaged as a\n",
    "matrix is:\n",
    "\n",
    "$$\\begin{bmatrix} x_{new} \\\\ y_{new} \\end{bmatrix} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} x_{new} \\\\ y_{new} \\end{bmatrix} = \\begin{bmatrix} ax + by \\\\ cx + dy \\end{bmatrix}$$\n",
    "\n",
    "$\\widehat{i}$ is the first column [a, c] and $\\widehat{j}$ is the column [b, d]. We package both of these basis vectors as a matrix, which again is a collection of vectors expressed as a grid of numbers in two or more dimensions. This transformation of a vector by applying basis vectors is known as matrix vector multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "# compose basis matrix with i-hat and j-hat\n",
    "basis = np.array(\n",
    "                    [[3, 0],\n",
    "                    [0, 2]]\n",
    "                )\n",
    "\n",
    "# declare vector v\n",
    "v = np.array([1,1])\n",
    "# create new vector\n",
    "# by transforming v with dot product\n",
    "new_v = basis.dot(v)\n",
    "print(new_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When thinking in terms of basis vectors, I prefer to break out the basis vectors and then compose them together into a matrix. Just note you will need to transpose, or swap the columns and rows. This is because NumPy’s array() function will do the opposite orientation we want, populating each vector as a row rather than a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "# Declare i-hat and j-hat\n",
    "i_hat = np.array([3, 0])\n",
    "j_hat = np.array([0, 2])\n",
    "\n",
    "# compose basis matrix using i-hat and j-hat\n",
    "# also need to transpose rows into columns\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "# declare vector v\n",
    "v = np.array([1,1])\n",
    "# create new vector\n",
    "# by transforming v with dot product\n",
    "new_v = basis.dot(v)\n",
    "print(new_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example that jumps things up a notch. Let’s take vector $\\overrightarrow{v}$  of value [2, 1]. $\\widehat{i}$  and $\\widehat{j}$ start at [1, 0] and [0, 1], but then are transformed and land at [2, 3] and [2, -1]. What happens to $\\overrightarrow{v}$  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5]\n"
     ]
    }
   ],
   "source": [
    "# Declare i-hat and j-hat\n",
    "i_hat = np.array([2, 3])\n",
    "j_hat = np.array([2, -1])\n",
    "# compose basis matrix using i-hat and j-hat\n",
    "# also need to transpose rows into columns\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "# declare vector v 0\n",
    "v = np.array([2,1])\n",
    "# create new vector\n",
    "# by transforming v with dot product\n",
    "new_v = basis.dot(v)\n",
    "print(new_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot has happened here. Not only did we scale $\\widehat{i}$  and $\\widehat{j}$ and elongate vector $\\overrightarrow{v}$. We actually sheared, rotated, and flipped space, too. You know space was flipped when $\\widehat{i}$  and $\\widehat{j}$ change places in their clockwise orientation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Think of matrix multiplication as applying multiple transformations to a vector space. Each transformation is like a function, where we apply the innermost first and then apply each subsequent transformation outward.\n",
    "\n",
    "Here is how we apply a rotation and then a shear to any vector $\\overrightarrow{v}$ with value [x, y]:\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$$\n",
    "\n",
    "$$\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} e & f \\\\ g & h \\end{bmatrix} = \\begin{bmatrix} ae+bg & af+bh \\\\ ce+de & cf+dh \\end{bmatrix}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED MATRIX:\n",
      " [[ 1 -1]\n",
      " [ 1  0]]\n",
      "[-1  1]\n",
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "# Transformation 1\n",
    "i_hat1 = np.array([0, 1])\n",
    "j_hat1 = np.array([-1, 0])\n",
    "transform1 = np.array([i_hat1, j_hat1]).transpose()\n",
    "# Transformation 2\n",
    "i_hat2 = np.array([1, 0])\n",
    "j_hat2 = np.array([1, 1])\n",
    "transform2 = np.array([i_hat2, j_hat2]).transpose()\n",
    "# Combine Transformations\n",
    "combined = transform2 @ transform1\n",
    "# Test\n",
    "print(\"COMBINED MATRIX:\\n {}\".format(combined))\n",
    "v = np.array([1, 2])\n",
    "print(combined.dot(v))\n",
    "\n",
    "# applying each transformation indicidually to vector v, you still get the same result\n",
    "\n",
    "rotated = transform1.dot(v)\n",
    "sheered = transform2.dot(rotated)\n",
    "print(sheered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED MATRIX:\n",
      " [[ 0 -1]\n",
      " [ 1  1]]\n",
      "[-2  3]\n"
     ]
    }
   ],
   "source": [
    "# Non cummutative nature of matrix multiplication\n",
    "# Transformation 1\n",
    "i_hat1 = np.array([0, 1])\n",
    "j_hat1 = np.array([-1, 0])\n",
    "transform1 = np.array([i_hat1, j_hat1]).transpose()\n",
    "# Transformation 2\n",
    "i_hat2 = np.array([1, 0])\n",
    "j_hat2 = np.array([1, 1])\n",
    "transform2 = np.array([i_hat2, j_hat2]).transpose()\n",
    "# Combine Transformations, apply sheer first and then rotation\n",
    "combined = transform1 @ transform2\n",
    "# Test\n",
    "print(\"COMBINED MATRIX:\\n {}\".format(combined))\n",
    "v = np.array([1, 2])\n",
    "print(combined.dot(v))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinants\n",
    "\n",
    "When we perform linear transformations, we sometimes “expand” or “squish” space and the degree this happens can be helpful. \n",
    "\n",
    "![Determinants](images/LinearAlgebra_Determinants.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i_hat = np.array([3, 0])\n",
    "j_hat = np.array([0, 2])\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "determinant = np.linalg.det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# A simple shear does not change the determinant\n",
    "\n",
    "i_hat = np.array([1, 0])\n",
    "j_hat = np.array([1, 1])\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "determinant = np.linalg.det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But scaling will increase or decrease the determinant, as that will increase/decrease the sampled area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.000000000000001\n"
     ]
    }
   ],
   "source": [
    "i_hat = np.array([-2, 1])\n",
    "j_hat = np.array([1, 2])\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "determinant = np.linalg.det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_vectors(matrix,color):\n",
    "    i_col=matrix[:,0]\n",
    "    j_col=matrix[:,1]\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.quiver(*origin, i_col, j_col, color=color, angles='xy', scale_units='xy', scale=1)\n",
    "    plt.annotate(f'i {i_col.tolist()}',xy=i_col,xytext=i_col*1.1)\n",
    "    plt.annotate(f'j {j_col.tolist()}',xy=j_col,xytext=j_col*1.1)\n",
    "    plt.grid()\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-2, 4)\n",
    "    plt.show()\n",
    "\n",
    "plot_vectors(matrix=basis,color=['r','b'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System of Equations and Inverse Matrices\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4x + 2y + 4z = 44\n",
    "5x + 3y + 7z = 56\n",
    "9x + 3y + 6z = 72\n",
    "\n",
    "$$A=\\begin{bmatrix} 4 & 2 & 4 \\\\ 5 & 3 & 7 \\\\ 9 & 3 & 6 \\end{bmatrix} \\ B=\\begin{bmatrix} 44 \\\\ 56 \\\\72 \\end{bmatrix} \\ X=\\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}$$\n",
    "$$AX=B$$\n",
    "\n",
    "to Find X $$ A^{-1}AX=A^{-1}B \\\\ X = A^{-1}B$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVERSE: Matrix([[-1/2, 0, 1/3], [11/2, -2, -4/3], [-2, 1, 1/3]])\n",
      "IDENTITY: Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "# 4x + 2y + 4z = 44\n",
    "# 5x + 3y + 7z = 56\n",
    "# 9x + 3y + 6z = 72\n",
    "A = Matrix([\n",
    "[4, 2, 4],\n",
    "[5, 3, 7],\n",
    "[9, 3, 6]\n",
    "])\n",
    "# dot product between A and its inverse\n",
    "# will produce identity function\n",
    "inverse = A.inv()\n",
    "identity = inverse * A\n",
    "# prints Matrix([[-1/2, 0, 1/3], [11/2, -2, -4/3], [-2, 1, 1/3]])\n",
    "print(\"INVERSE: {}\".format(inverse))\n",
    "# prints Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "print(\"IDENTITY: {}\".format(identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2. 34. -8.]\n"
     ]
    }
   ],
   "source": [
    "# 4x + 2y + 4z = 44\n",
    "# 5x + 3y + 7z = 56\n",
    "# 9x + 3y + 6z = 72\n",
    "A = np.array([\n",
    "[4, 2, 4],\n",
    "[5, 3, 7],\n",
    "[9, 3, 6]\n",
    "])\n",
    "B = np.array([\n",
    "44,\n",
    "56,\n",
    "72\n",
    "])\n",
    "X = np.linalg.inv(A).dot(B)\n",
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EigenVectors $\\nu$ and EigenValues $\\lambda$\n",
    "Matrix decomposition is breaking up a matrix into its basic components, much like factoring numbers (e.g., 10 can be factored to 2 × 5). Matrix decomposition is helpful for tasks like finding inverse matrices and calculating determinants, as well as linear regression. . For now, just know eigendecomposition is helpful for breaking up a matrix into components that are easier to work with in different machine learning tasks. In eigendecomposition, there are two components: the eigenvalues denoted by lambda $\\lambda$ and eigenvector by $\\nu$\n",
    "\n",
    "![EigenVectors and EigenValues](images/LinearAlgebra_EigenVectors.png)\n",
    "\n",
    "if we have a square matrix A, it the following eigenvalue equation\n",
    "\n",
    "$$A\\nu = \\lambda\\nu$$\n",
    "\n",
    "\n",
    "If A is the original matrix, it is composed of eigenvector vand eigenvalue λ. There is one eigenvector and eigenvalue for each dimension of the parent matrix, and not all matrices can be decomposed into an eigenvector and eigenvalue. Sometimes complex (imaginary) numbers will even result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIGENVALUES [-0.46410162  6.46410162]\n",
      "\n",
      "EIGENVECTORS\n",
      "[[-0.80689822 -0.34372377]\n",
      " [ 0.59069049 -0.9390708 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [4, 5]\n",
    "    ])\n",
    "eigenvals, eigenvecs = np.linalg.eig(A)\n",
    "print(\"EIGENVALUES\",eigenvals)\n",
    "print(\"\\nEIGENVECTORS\",eigenvecs,sep=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we rebuild matrix A from the eigenvectors and eigenvalues? Recall this formula:\n",
    "    \n",
    "$$A\\nu = \\lambda\\nu$$\n",
    "We need to make a few tweaks to the formula to reconstruct A:\n",
    "$$A = Q\\Lambda Q^{-1}$$\n",
    "In this new formula, $Q$ is the eigenvectors, $\\Lambda$ is the eigenvalues in diagonal form, and $Q^{-1}$ is the inverse matrix of Q. Diagonal form means the vector is padded into\n",
    "a matrix of zeroes and occupies the diagonal line in a similar pattern to an identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIGENVALUES\n",
      "[-0.46410162  6.46410162]\n",
      "\n",
      "EIGENVECTORS\n",
      "[[-0.80689822 -0.34372377]\n",
      " [ 0.59069049 -0.9390708 ]]\n",
      "\n",
      "REBUILD MATRIX\n",
      "[[1. 2.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# Decomposing and recomposing a matrix\n",
    "\n",
    "A = np.array([\n",
    "        [1, 2],\n",
    "        [4, 5]\n",
    "        ])\n",
    "eigenvals, eigenvecs = np.linalg.eig(A)\n",
    "print(\"EIGENVALUES\")\n",
    "print(eigenvals)\n",
    "print(\"\\nEIGENVECTORS\")\n",
    "print(eigenvecs)\n",
    "\n",
    "print(\"\\nREBUILD MATRIX\")\n",
    "Q = eigenvecs\n",
    "R = np.linalg.inv(Q)\n",
    "L = np.diag(eigenvals)\n",
    "\n",
    "B = Q @ L @ R\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "643ce797ddba7af60514a7b3d7bbed7015dde014b0e037668c33e29908f2b7a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

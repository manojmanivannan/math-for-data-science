{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Classification\n",
    "\n",
    "logistic regression is a type of regression that predicts a probability of an outcome given one or more independent variables. This in turn can be used for classification, which is predicting categories rather than real numbers as we did with linear regression.\n",
    "\n",
    "We are not always interested in representing variables as continuous, where they can represent an infinite number of real decimal values. There are situations where we would rather variables be discrete, or representative of whole numbers, integers, or booleans (1/0, true/false). Logistic regression is trained on an output variable that is discrete (a binary 1 or 0) or a categorical number (which is a whole number). It does output a continuous variable in the form of probability, but that can be converted into a discrete value with a threshold.\n",
    "\n",
    "**Understanding logistic Regression**\n",
    "\n",
    "Imagine there was a small industrial accident and you are trying to understand the\n",
    "impact of chemical exposure. You have 11 patients who were exposed for differing\n",
    "numbers of hours to this chemical. Some have shown symptoms (value of 1) and others have not shown symptoms.\n",
    "\n",
    "<img src=\"images/LogisticRegression_understanding.png\" height=\"300px\">\n",
    "\n",
    "Doing a cursory analysis on this sample, we can say that there is nearly 0% probability a patient exposed for fewer than four hours will show symptoms, but there is 100% probability for greater than four hours. Between these two groups, there is an immediate jump to showing symptoms at approximately four hours.\n",
    "\n",
    "Of course, nothing is ever this clear-cut in the real world. Let’s say you gathered more data, where the middle of the range has a mix of patients showing symptoms versus not showing symptoms\n",
    "\n",
    "<img src=\"images/LogisticRegression_understanding_1.png\" height=\"250px\">\n",
    "\n",
    "Because of this overlap of points in the middle, there is no distinct cutoff when\n",
    "patients show symptoms but rather a gradual transition from 0% probability to 100%\n",
    "probability (0 and 1). This example demonstrates how a logistic regression results in a curve indicating a probability of belonging to the true category (a patient showed symptoms) across an independent variable (hours of exposure).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Function\n",
    "\n",
    "The logistic function is an S-shaped curve (also known as a sigmoid curve) that, for a given set of input variables, produces an output variable between 0 and 1. Because the output variable is between 0 and 1 it can be used to represent a probability\n",
    "\n",
    "Probability y for one input variable x:\n",
    "$$ y = \\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x)}} $$\n",
    "\n",
    "The exponent  looks identical to $y = mx + b$ or $y = \\beta_0 + \\beta_1 x$.\n",
    "This linear function in the exponent is known as the log-odds function, but for now just know this whole logistic function produces this S-shaped curve we need to output a shifting probability across an x-value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def predict_probability(x, b0, b1):\n",
    "    p = 1.0 / (1.0 + math.exp(-(b0 + b1 * x)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/(1.0 + 16.8272567955368*exp(-0.62*x))\n"
     ]
    }
   ],
   "source": [
    "# Lets plot to see what it looks like and assumg \n",
    "# b0=-2.823 and \n",
    "# b1= 0.62\n",
    "\n",
    "from sympy import *\n",
    "\n",
    "b0, b1, x = symbols('b0 b1 x')\n",
    "\n",
    "p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "\n",
    "p = p.subs(b0,-2.823).subs(b1, 0.62)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x27c9c022fa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extend logistic regression to more than one input variable (x1, x2, ... xn).\n",
    "$$ y = \\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n)}} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the logistic Curve\n",
    "\n",
    "The data can have any mix of decimal, integer, and binary variables, but the output variable must be binary (0 or 1). When we actually do prediction, the output variable will be between 0 and 1, resembling a probability.\n",
    "\n",
    "The data provides our input and output variable values, but we need to solve for the $β_0$ and $β_1$ coefficients to fit our logistic function. Instead of inizing **least squares**, we use **maximum likelihood estimation**, which, as the name suggests, maximizes the likelihood a given logistic curve would output the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69267212]\n",
      "[-3.17576395]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\")\n",
    "\n",
    "# Extract input variables (all rows, all columns but last column)\n",
    "X = df.values[:, :-1]\n",
    "\n",
    "# Extract output column (all rows, last column)\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "# Perform logistic regression\n",
    "# Turn off penalty\n",
    "model = LogisticRegression(penalty=None)\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "# print beta1\n",
    "print(model.coef_.flatten()) \n",
    "\n",
    "# print beta0\n",
    "print(model.intercept_.flatten()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make specific predictions, use the predict() and predict_prob() functions on\n",
    "the model object in SciPy, whether it is a LogisticRegression or any other type of\n",
    "classification model. The predict() function will predict a specific class (e.g., True 1.0 or False 1.0) while the predict_prob() will output probabilities for each class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Maximum likelihood and Gradient Descent\n",
    "\n",
    "Given coefficients β0 = –3.17576395 and β1 = 0.69267212, below code shows how we\n",
    "calculate the joint likelihood for this data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7911180221699105e-05\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "patient_data = pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\").itertuples()\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "def logistic_function(x):\n",
    "    p = 1.0 / (1.0 + math.exp(-(b0 + b1 * x)))\n",
    "    return p\n",
    "\n",
    "# Calculate the joint likelihood\n",
    "joint_likelihood = 1.0\n",
    "for p in patient_data:\n",
    "    if p.y == 1.0:\n",
    "        joint_likelihood *= logistic_function(p.x)\n",
    "    elif p.y == 0.0:\n",
    "        joint_likelihood *= (1.0 - logistic_function(p.x))\n",
    "\n",
    "print(joint_likelihood)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compress this `if` statement , mathematically it looks like this\n",
    "\n",
    "$$ \\text{joint likelihood} = \\prod_{i=1}^{n} \\left(\\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x_i)}}\\right)^{y_i} \\text{x}\\ \\left(\\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x_i)}}\\right)^{1.0-y_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "joint_likelihood=1.0\n",
    "\n",
    "for p in patient_data:\n",
    "    joint_likelihood *= logistic_function(p.x) ** p.y * \\\n",
    "        (1.0 - logistic_function(p.x)) ** (1.0 - p.y)\n",
    "\n",
    "print(joint_likelihood)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT 1.0 ??? WHY ?\n",
    "Note that computers can get overwhelmed multiplying several small decimals\n",
    "together, known as floating point underflow. There is a clever mathematical hack to get around this. You can take the `log()` of each decimal you are multiplying and instead add them together. and you can then call the `exp()` function to convert the total sum back to get the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.791118022169896e-05\n"
     ]
    }
   ],
   "source": [
    "patient_data = pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\").itertuples()\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "# Calculate the joint likelihood\n",
    "joint_likelihood = 0.0\n",
    "\n",
    "for p in patient_data:\n",
    "    joint_likelihood += math.log(logistic_function(p.x) ** p.y * \\\n",
    "        (1.0 - logistic_function(p.x)) ** (1.0 - p.y))\n",
    "\n",
    "joint_likelihood = math.exp(joint_likelihood)\n",
    "print(joint_likelihood)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let’s just allow SymPy to do the partial derivatives for us, for $β_0$ and $β_1$ respectively. We will then immediately compile and use them for gradient descent,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6926693075370813 -3.1757515504098213\n"
     ]
    }
   ],
   "source": [
    "# expressing the same in SymPy\n",
    "\n",
    "from sympy import *\n",
    "import pandas as pd\n",
    "points = list(pd.read_csv(\"https://tinyurl.com/y2cocoo7\").itertuples())\n",
    "b1, b0, i, n = symbols('b1 b0 i n')\n",
    "x, y = symbols('x y', cls=Function)\n",
    "\n",
    "joint_likelihood = Sum(log((1.0 / (1.0 + exp(-(b0 + b1 * x(i))))) ** y(i) \\\n",
    "* (1.0 - (1.0 / (1.0 + exp(-(b0 + b1 * x(i)))))) ** (1 - y(i))), (i, 0, n))\n",
    "\n",
    "# Partial derivative for m, with points substituted\n",
    "d_b1 = diff(joint_likelihood, b1) \\\n",
    "        .subs(n, len(points) - 1).doit() \\\n",
    "            .replace(x, lambda i: points[i].x) \\\n",
    "                .replace(y, lambda i: points[i].y)\n",
    "\n",
    "# Partial derivative for m, with points substituted\n",
    "d_b0 = diff(joint_likelihood, b0) \\\n",
    "        .subs(n, len(points) - 1).doit() \\\n",
    "            .replace(x, lambda i: points[i].x) \\\n",
    "                .replace(y, lambda i: points[i].y)\n",
    "\n",
    "# compile using lambdify for faster computation\n",
    "d_b1 = lambdify([b1, b0], d_b1)\n",
    "d_b0 = lambdify([b1, b0], d_b0)\n",
    "\n",
    "# Perform Gradient Descent\n",
    "b1 = 0.01\n",
    "b0 = 0.01\n",
    "L = .01\n",
    "\n",
    "for j in range(10_000):\n",
    "    b1 += d_b1(b1, b0) * L\n",
    "    b0 += d_b0(b1, b0) * L\n",
    "\n",
    "print(b1, b0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable Logistic Regression\n",
    "\n",
    "| SEX | AGE | PROMOTIONS | YEARS_EMPLOYED | DID_QUIT |\n",
    "|:---:|:---:|------------|----------------|----------|\n",
    "| 1   | 32  | 3          | 7              | 0        |\n",
    "| 1   | 34  | 2          | 5              | 0        |\n",
    "| 1   | 29  | 2          | 5              | 1        |\n",
    "| 0   | 42  | 4          | 10             | 0        |\n",
    "| 1   | 43  | 4          | 10             | 0        |\n",
    "\n",
    "$$ y = \\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n)}} $$\n",
    "\n",
    "\n",
    "We will create βcoefficients for each of the variables sex, age, promotions, and\n",
    "years_employed. The output variable did_quit is binary, and that is going to drive the logistic regression outcome we are predicting. Because we are dealing with multiple dimensions, it is going to be hard to visualize the curvy hyperplane that is our logistic curve. So we will steer clear from visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manoj\\Documents\\MANOJ\\Gitlab\\math-for-data-science\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COEFFICIENTS: [ 0.03213405  0.03682453 -2.50410028  0.9742266 ]\n",
      "INTERCEPT: [-2.73485302]\n",
      "WILL LEAVE: [[0.02918934 0.97081066]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manoj\\Documents\\MANOJ\\Gitlab\\math-for-data-science\\venv\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\manoj\\Documents\\MANOJ\\Gitlab\\math-for-data-science\\venv\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "employee_data = pd.read_csv(\"https://tinyurl.com/y6r7qjrp\")\n",
    "\n",
    "# grab independent variable columns\n",
    "inputs = employee_data.iloc[:, :-1]\n",
    "\n",
    "# grab dependent \"did_quit\" variable column\n",
    "output = employee_data.iloc[:, -1]\n",
    "\n",
    "# build logistic regression\n",
    "fit = LogisticRegression(penalty='none').fit(inputs, output)\n",
    "\n",
    "# Print coefficients:\n",
    "print(\"COEFFICIENTS: {0}\".format(fit.coef_.flatten()))\n",
    "print(\"INTERCEPT: {0}\".format(fit.intercept_.flatten()))\n",
    "\n",
    "# Interact and test with new employee data\n",
    "def predict_employee_will_stay(sex, age, promotions, years_employed):\n",
    "    prediction = fit.predict([[sex, age, promotions, years_employed]])\n",
    "    probabilities = fit.predict_proba([[sex, age, promotions, years_employed]])\n",
    "    if prediction == [[1]]:\n",
    "        return \"WILL LEAVE: {0}\".format(probabilities)\n",
    "    else:\n",
    "        return \"WILL STAY: {0}\".format(probabilities)\n",
    "\n",
    "# Test a prediction\n",
    "n = input(\"Predict employee will stay or leave {sex},{age},{promotions},{years_employed}: \")\n",
    "(sex, age, promotions, years_employed) = n.split(\",\")\n",
    "print(predict_employee_will_stay(int(sex), int(age), int(promotions), int(years_employed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the coefficients for sex, age, promotions, and years_employed\n",
    "are displayed in that order. By the weight of the coefficients, you can see that sex and age play very little role in the prediction (they both have a weight near 0). However, promotions and years_employed have significant weights of –2.504 and 0.97. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Log-Odds\n",
    "It has always been a interest to mathematicians to take a linear function and scale its output to fall between 0 and 1, and therefore be useful for predicting probability. The log-odds, also called the logit function, lends itself to logistic regression for this purpose.\n",
    "\n",
    "\n",
    "$$ y = \\frac {1.0} {1.0 + e^{-(\\beta_0 + \\beta_1 x)}} $$\n",
    "\n",
    "This linear function being raised to e is known as the log-odds function, which takes the logarithm of the odds for the event of interest. \n",
    "\n",
    "As an example, let’s use our logistic regression from earlier where Β0 = -3.17576395 and Β1 = 0.69267212. What is the probability of showing symptoms after six hours, where x = 6? \n",
    "\n",
    "$$ p = \\frac {1.0} {1.0 + e^{-(-3.1757 + 0.6926 (6))}} = 0.727216 $$\n",
    "\n",
    "$$ odds = \\frac {p} {1-p} $$\n",
    "$$ odds = \\frac {0.72716} {1-0.72716} $$\n",
    "\n",
    "So at six hours, a patient is 2.66517 times more likely to show symptoms than not\n",
    "show symptoms. When we wrap the odds function in a natural logarithm (a logarithm with base e), we call this the logit function. The output of this formula is what we call the log-odds, named…shockingly…because we take the logarithm of the odds:\n",
    "\n",
    "$$ logit = log \\left(\\frac {p} {1-p}\\right) $$\n",
    "$$ logit = log \\left(\\frac {0.72716} {1-0.72716}\\right) = 0.98026 $$\n",
    "\n",
    "Our log-odds at six hours is 0.9802687. What does this mean and why do we care?\n",
    "When we are in “log-odds land” it is easier to compare one set of odds against\n",
    "another. We treat anything greater than 0 as favoring odds an event will happen,\n",
    "whereas anything less than 0 is against an event. A log-odds of –1.05 is linearly the same distance from 0 as 1.05. In plain odds, though, the equivalents are 0.3499 and 2.857, respectively, which is not as interpretable. That is the convenience of log-odds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall I said the linear function in our logistic regression formula β0 + β1x is our log-odds function. Check this out:\n",
    "\n",
    "log‐odds = β0 + β1x\n",
    "\n",
    "log‐odds = − 3.17576395 + 0.69267212 6\n",
    "\n",
    "log‐odds = 0.98026877\n",
    "\n",
    "It’s the same value 0.98026877 as our previous calculation, the odds of our logistic regression at x = 6 and then taking the log() of it! So what is the link? What ties all this together? Given a probability from a logistic regression p and input variable x, it is this:\n",
    "\n",
    "$$ log \\left(\\frac {p} {1-p}\\right) = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "<img src=\"images/LogisticRegression_logodds.png\" height=\"250px\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure when the log-odds is 0.0 on the line, then the probability of the logistic curve is at 0.5. This makes sense because when our odds are fair at 1.0, the probability is going to be 0.50 as shown in the logistic regression, and the log-odds are going to be 0 as shown by the line.\n",
    "\n",
    "Let’s first find the probabilities of symptoms for six hours and eight hours,\n",
    "respectively\n",
    "\n",
    "<img src=\"images/LogisticRegression_logodds_calc.png\">\n",
    "\n",
    "We get a value of approximately 3.996, meaning that our odds of showing symptoms increases by nearly a factor of four with an extra two hours of exposure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643ce797ddba7af60514a7b3d7bbed7015dde014b0e037668c33e29908f2b7a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
